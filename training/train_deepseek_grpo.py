"""
DeepSeek GRPOè®­ç»ƒè„šæœ¬

åŸºäºDeepSeek-Math-V2çš„è‡ªéªŒè¯æœºåˆ¶ï¼Œé›†æˆåˆ°ç°æœ‰çš„GRPOè®­ç»ƒæ¡†æ¶
å®ç°ï¼šè¿‡ç¨‹å¥–åŠ±å¾®è°ƒ + ä¸‰å±‚éªŒè¯ + è¿­ä»£ä¼˜åŒ–
"""

import os
import sys
import warnings
import yaml
import logging
import torch
from pathlib import Path
from typing import Optional, Dict, Any, List
from dataclasses import dataclass, field
from datetime import datetime
from transformers import AutoModelForCausalLM, AutoTokenizer
from trl import GRPOTrainer, GRPOConfig
from accelerate import Accelerator
from peft import LoraConfig, get_peft_model

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

from data.data_loader import NL2SQLDataLoader
from deepseek_sql import DeepSeekNL2SQL
from training.train_utils import WandBLogger, CheckpointManager, PerformanceMonitor, Logger, GPUMonitor
from utils.tensorboard_logger import TensorBoardLogger

logger = logging.getLogger(__name__)


@dataclass
class DeepSeekTrainingConfig:
    """DeepSeek GRPOè®­ç»ƒé…ç½®"""
    # æ¨¡å‹é…ç½®
    model_name: str = "Qwen/Qwen3-1.7B"
    torch_dtype: str = "bfloat16"
    load_in_4bit: bool = False
    load_in_8bit: bool = False
    trust_remote_code: bool = True

    # æ•°æ®é…ç½®
    train_file: str = ""
    test_file: str = ""
    val_split: float = 0.1

    # è®­ç»ƒé…ç½®
    output_dir: str = "./outputs/deepseek_checkpoints"
    num_train_epochs: int = 3
    per_device_train_batch_size: int = 4  # ç”±äºDeepSeekå¼€é”€å¤§ï¼Œå‡å°‘æ‰¹æ¬¡å¤§å°
    per_device_eval_batch_size: int = 8
    gradient_accumulation_steps: int = 4  # å¢åŠ æ¢¯åº¦ç´¯ç§¯æ¥è¡¥å¿
    learning_rate: float = 5e-6  # é™ä½å­¦ä¹ ç‡
    lr_scheduler_type: str = "cosine"
    warmup_steps: int = 100
    max_grad_norm: float = 1.0
    weight_decay: float = 0.01
    bf16: bool = True
    tf32: bool = True

    # DeepSeeké…ç½®
    deepseek_max_rounds: int = 3
    deepseek_n_generations_per_round: int = 2
    deepseek_n_verifications_per_generation: int = 2
    deepseek_process_reward_weight: float = 0.7  # è¿‡ç¨‹å¥–åŠ±æƒé‡
    deepseek_final_reward_weight: float = 0.3   # æœ€ç»ˆç»“æœå¥–åŠ±æƒé‡

    # VLMéªŒè¯å™¨é…ç½®
    vlm_enabled: bool = False  # æ˜¯å¦å¯ç”¨VLMéªŒè¯å™¨
    vlm_model_path: Optional[str] = None  # VLMæ¨¡å‹è·¯å¾„
    vlm_verification_weight: float = 0.8  # VLMéªŒè¯æƒé‡

    # GRPOé…ç½®
    num_generations: int = 4
    temperature: float = 0.7
    top_p: float = 0.95
    top_k: int = 50
    max_new_tokens: int = 1024

    # è¯„ä¼°å’Œä¿å­˜é…ç½®
    eval_steps: int = 200  # å‡å°‘è¯„ä¼°é¢‘ç‡
    save_steps: int = 200  # å‡å°‘ä¿å­˜é¢‘ç‡
    save_total_limit: int = 3
    logging_steps: int = 20
    logging_dir: str = "./outputs/logs"

    # TensorBoard é…ç½®
    tensorboard_port: int = 6007
    auto_start_tensorboard: bool = True
    tensorboard_log_dir: str = "./outputs/deepseek_checkpoints/logs"

    # W&Bé…ç½®
    wandb_enabled: bool = True
    wandb_project: str = "qwen3-nl2sql-deepseek-grpo"
    wandb_entity: Optional[str] = None
    wandb_name: str = "deepseek_process_reward_training"

    # ç¡¬ä»¶é…ç½®
    num_gpus: int = 8
    seed: int = 42

    # æ£€æŸ¥ç‚¹é…ç½®
    resume_from_checkpoint: Optional[str] = None


class DeepSeekGRPOTrainer:
    """DeepSeek GRPOè®­ç»ƒå™¨"""

    def __init__(self, config: DeepSeekTrainingConfig):
        """
        åˆå§‹åŒ–DeepSeek GRPOè®­ç»ƒå™¨

        Args:
            config: è®­ç»ƒé…ç½®
        """
        self.config = config
        self._setup_logging()
        self._setup_environment()
        self._initialize_components()

    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        import warnings

        # è¿‡æ»¤è­¦å‘Š
        warnings.filterwarnings("ignore")
        os.environ['PYTHONWARNINGS'] = 'ignore'

        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(f'./outputs/logs/deepseek_training_{self.config.seed}.log'),
                logging.StreamHandler()
            ]
        )

        # æŠ‘åˆ¶urllib3è¯¦ç»†æ—¥å¿—
        logging.getLogger("urllib3").setLevel(logging.ERROR)

    def _setup_environment(self):
        """è®¾ç½®ç¯å¢ƒ"""
        # åˆ›å»ºè¾“å‡ºç›®å½•
        Path(self.config.output_dir).mkdir(parents=True, exist_ok=True)
        Path("./outputs/logs").mkdir(parents=True, exist_ok=True)
        Path("./outputs/deepseek_proof_pool").mkdir(parents=True, exist_ok=True)

        # è®¾ç½®éšæœºç§å­
        torch.manual_seed(self.config.seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(self.config.seed)

    def _initialize_components(self):
        """åˆå§‹åŒ–ç»„ä»¶"""
        logger.info("Initializing DeepSeek GRPO components...")

        # åˆå§‹åŒ–TensorBoardæ—¥å¿—è®°å½•å™¨
        self.tb_logger = TensorBoardLogger(
            log_dir=self.config.tensorboard_log_dir,
            experiment_name=f"deepseek-grpo-{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            port=self.config.tensorboard_port,
            auto_start=self.config.auto_start_tensorboard
        )

        # åˆå§‹åŒ–W&B
        if self.config.wandb_enabled:
            self.wandb_logger = WandBLogger(
                project=self.config.wandb_project,
                entity=self.config.wandb_entity,
                name=self.config.wandb_name,
                config=self.config
            )
        else:
            self.wandb_logger = None

        # åˆå§‹åŒ–æ£€æŸ¥ç‚¹ç®¡ç†å™¨
        self.checkpoint_manager = CheckpointManager(
            output_dir=self.config.output_dir,
            save_total_limit=self.config.save_total_limit
        )

        # åˆå§‹åŒ–æ€§èƒ½ç›‘æ§å™¨
        self.performance_monitor = PerformanceMonitor()

        # åŠ è½½æ•°æ®
        logger.info("Loading training data...")
        self.data_loader = NL2SQLDataLoader()
        self.train_examples = self.data_loader.load(self.config.train_file)

        # Split into train and validation
        val_size = int(len(self.train_examples) * self.config.val_split)
        self.train_dataset = self.train_examples[:-val_size]
        self.val_dataset = self.train_examples[-val_size:]

        logger.info(f"Train dataset size: {len(self.train_dataset)}")
        logger.info(f"Validation dataset size: {len(self.val_dataset)}")

        # åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
        logger.info(f"Loading model: {self.config.model_name}")
        self.tokenizer = AutoTokenizer.from_pretrained(
            self.config.model_name,
            trust_remote_code=True,
            padding_side="left"
        )
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token

        dtype_map = {
            "float32": torch.float32,
            "float16": torch.float16,
            "bfloat16": torch.bfloat16
        }
        torch_dtype = dtype_map.get(self.config.torch_dtype, torch.bfloat16)

        self.model = AutoModelForCausalLM.from_pretrained(
            self.config.model_name,
            torch_dtype=torch_dtype,
            device_map="auto",
            trust_remote_code=True
        )

        # åˆå§‹åŒ–DeepSeek NL2SQLç³»ç»Ÿ
        logger.info("Initializing DeepSeek NL2SQL system...")
        vlm_model_path = None
        if hasattr(self.config, 'vlm_enabled') and self.config.vlm_enabled:
            vlm_model_path = getattr(self.config, 'vlm_model_path', None)
            logger.info(f"VLM verification enabled with model: {vlm_model_path}")

        self.deepseek_system = DeepSeekNL2SQL(
            model_name=self.config.model_name,
            pool_dir="./outputs/deepseek_proof_pool",
            vlm_model_path=vlm_model_path
        )

        logger.info("Component initialization completed")

    def train(self):
        """å¼€å§‹è®­ç»ƒ"""
        logger.info("=" * 50)
        logger.info("å¼€å§‹ DeepSeek GRPO è®­ç»ƒ")
        logger.info("=" * 50)

        logger.info("Starting DeepSeek GRPO training...")
        logger.info(f"Training data size: {len(self.train_dataset)}")
        logger.info(f"Validation data size: {len(self.val_dataset)}")
        logger.info(f"DeepSeek max rounds: {self.config.deepseek_max_rounds}")

        self.performance_monitor.start()

        try:
            # å‡†å¤‡è®­ç»ƒæ•°æ®
            train_data = self._prepare_training_data()

            # é…ç½®GRPO
            grpo_config = GRPOConfig(
                output_dir=self.config.output_dir,
                num_train_epochs=self.config.num_train_epochs,
                per_device_train_batch_size=self.config.per_device_train_batch_size,
                per_device_eval_batch_size=self.config.per_device_eval_batch_size,
                gradient_accumulation_steps=self.config.gradient_accumulation_steps,
                learning_rate=self.config.learning_rate,
                lr_scheduler_type=self.config.lr_scheduler_type,
                warmup_steps=self.config.warmup_steps,
                max_grad_norm=self.config.max_grad_norm,
                weight_decay=self.config.weight_decay,
                num_generations=self.config.num_generations,
                temperature=self.config.temperature,
                top_p=self.config.top_p,
                top_k=self.config.top_k,
                max_new_tokens=self.config.max_new_tokens,
                eval_steps=self.config.eval_steps,
                save_steps=self.config.save_steps,
                save_total_limit=self.config.save_total_limit,
                logging_steps=self.config.logging_steps,
                seed=self.config.seed,
                bf16=self.config.bf16,
                tf32=self.config.tf32,
                report_to=[],
                remove_unused_columns=False,
            )

            # åˆ›å»ºTensorBoardå›è°ƒ
            from utils.tensorboard_callback import TensorBoardCallback
            tb_callback = TensorBoardCallback(self.tb_logger)

            # åˆ›å»ºGRPOè®­ç»ƒå™¨
            grpo_trainer = GRPOTrainer(
                model=self.model,
                processing_class=self.tokenizer,
                args=grpo_config,
                train_dataset=train_data,
                eval_dataset=self.val_dataset,
                reward_funcs=[self._deepseek_reward_function],
                callbacks=[tb_callback],
            )

            # å¼€å§‹è®­ç»ƒ
            logger.info("è®­ç»ƒå¼€å§‹...")
            train_result = grpo_trainer.train(resume_from_checkpoint=self.config.resume_from_checkpoint)

            # è®°å½•è®­ç»ƒç»“æœ
            logger.info("=" * 50)
            logger.info("è®­ç»ƒå®Œæˆ")
            logger.info(f"æœ€ç»ˆæŸå¤±: {train_result.training_loss}")
            logger.info("=" * 50)

            # ä¿å­˜æœ€ç»ˆæ¨¡å‹
            final_model_dir = Path(self.config.output_dir) / "final_model"
            self.model.save_pretrained(final_model_dir)
            self.tokenizer.save_pretrained(final_model_dir)
            logger.info(f"æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜: {final_model_dir}")

            # ä¸Šä¼ åˆ°W&B
            if self.config.wandb_enabled and self.wandb_logger:
                self.wandb_logger.log_model(str(final_model_dir), "final_model")

            # ä¿å­˜æ€§èƒ½æŠ¥å‘Š
            self._save_performance_report()

        except Exception as e:
            logger.error(f"è®­ç»ƒå‡ºé”™: {e}")
            raise
        finally:
            # å®ŒæˆTensorBoardè®°å½•
            logger.info("æ­£åœ¨ä¿å­˜è®­ç»ƒæ—¥å¿—...")
            self.tb_logger.finish()

            # åœæ­¢TensorBoardæœåŠ¡å™¨ï¼ˆå¦‚æœæ˜¯è‡ªåŠ¨å¯åŠ¨çš„ï¼‰
            self.tb_logger.stop_tensorboard_server()

            # å®ŒæˆW&B
            if self.config.wandb_enabled and self.wandb_logger:
                self.wandb_logger.finish()

        logger.info("DeepSeek GRPO training completed")

    def _save_performance_report(self):
        """ä¿å­˜æ€§èƒ½æŠ¥å‘Š"""
        report = self.performance_monitor.get_metrics_summary()
        report_path = Path(self.config.output_dir) / "performance_report.txt"

        with open(report_path, 'w') as f:
            f.write("=" * 50 + "\n")
            f.write("NL2SQL DeepSeek GRPOè®­ç»ƒæ€§èƒ½æŠ¥å‘Š\n")
            f.write("=" * 50 + "\n\n")

            for key, value in report.items():
                f.write(f"{key}: {value}\n")

        logger.info(f"æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

    def _prepare_training_data(self) -> List[Dict[str, Any]]:
        """å‡†å¤‡è®­ç»ƒæ•°æ®ï¼ˆå¹¶è¡Œå¤„ç†ï¼‰"""
        logger.info("Preparing training data with DeepSeek processing (parallel mode)...")

        training_data = []

        # ä½¿ç”¨å¹¶è¡Œå¤„ç†åŠ é€Ÿæ•°æ®å‡†å¤‡
        from concurrent.futures import ProcessPoolExecutor, as_completed
        import os

        # é™åˆ¶å¹¶è¡Œè¿›ç¨‹æ•° = CPUæ ¸å¿ƒæ•°æˆ–4ï¼Œå–è¾ƒå°å€¼
        num_workers = min(os.cpu_count() or 4, 4)
        logger.info(f"Using {num_workers} workers for parallel processing")

        # å‡†å¤‡æ‰€æœ‰æ ·æœ¬çš„å‚æ•°
        sample_params = []
        for i, example in enumerate(self.train_dataset[:100]):  # é™åˆ¶100ä¸ªæ ·æœ¬
            query = example.query
            response = example.response
            reference_type = example.complexity_type
            reference_sql = example.sql

            # ä»queryä¸­æå–ç»„ä»¶
            schema, knowledge, examples = self._parse_query_components(query)
            actual_query = self._extract_question_from_query(query)

            if not actual_query or not schema:
                continue

            sample_params.append({
                'idx': i,
                'query': actual_query,
                'schema': schema,
                'knowledge': knowledge,
                'examples': examples,
                'reference_type': reference_type,
                'reference_sql': reference_sql,
                'model_name': self.config.model_name,
                'pool_dir': "./outputs/deepseek_proof_pool",
                'vlm_model_path': self.config.vlm_model_path if hasattr(self.config, 'vlm_enabled') and self.config.vlm_enabled else None
            })

        logger.info(f"Processing {len(sample_params)} samples in parallel...")

        # å¹¶è¡Œå¤„ç†æ ·æœ¬
        with ProcessPoolExecutor(max_workers=num_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_idx = {
                executor.submit(_process_single_sample, params): params['idx']
                for params in sample_params
            }

            # æ”¶é›†ç»“æœ
            processed_count = 0
            for future in as_completed(future_to_idx):
                idx = future_to_idx[future]
                try:
                    result = future.result()
                    if result and result.get('success', False):
                        training_data.append(result['data'])
                        processed_count += 1

                    # è¿›åº¦æŠ¥å‘Š
                    if (processed_count + len(training_data)) % 10 == 0:
                        logger.info(f"Completed {(processed_count + len(training_data))}/{len(sample_params)} samples...")

                except Exception as e:
                    logger.debug(f"Error processing sample {idx}: {e}")

        logger.info(f"Training data preparation completed: {len(training_data)} samples ready from {len(sample_params)} attempts")
        return training_data

    def _deepseek_reward_function(self, prompts: List[str], responses: List[str],
                                 references: List[str], **kwargs) -> List[float]:
        """
        DeepSeekè¿‡ç¨‹å¥–åŠ±å‡½æ•°

        Args:
            prompts: æç¤ºåˆ—è¡¨
            responses: ç”Ÿæˆçš„å“åº”åˆ—è¡¨
            references: å‚è€ƒç­”æ¡ˆåˆ—è¡¨

        Returns:
            å¥–åŠ±åˆ†æ•°åˆ—è¡¨
        """
        rewards = []

        for i, (prompt, response, reference) in enumerate(zip(prompts, responses, references)):
            try:
                # è§£æç»„ä»¶
                query, schema, knowledge, examples = self._parse_training_prompt(prompt)

                if not all([query, schema, response]):
                    rewards.append(0.0)
                    continue

                # è§£æç”Ÿæˆçš„å“åº”
                generated_sql = self._extract_sql_from_response(response)
                thinking = self._extract_thinking_from_response(response)
                self_eval = self._extract_self_eval_from_response(response)

                if not generated_sql:
                    rewards.append(0.0)
                    continue

                # ä½¿ç”¨DeepSeekç³»ç»Ÿè¿›è¡Œè¯„åˆ†
                deepseek_result = self.deepseek_system.process_query(
                    query=query,
                    schema=schema,
                    knowledge=knowledge,
                    examples=examples,
                    problem_idx=f"eval_{i}"
                )

                if deepseek_result.get('success', False):
                    # è·å–è¿‡ç¨‹å¥–åŠ±
                    process_reward = deepseek_result.get('process_reward', {})
                    total_process_reward = process_reward.get('total_process_reward', 0.0)

                    # è·å–æœ€ç»ˆç»“æœåˆ†æ•°
                    best_score = deepseek_result.get('best_score', 0.0)

                    # ç»„åˆå¥–åŠ±
                    combined_reward = (
                        total_process_reward * self.config.deepseek_process_reward_weight +
                        best_score * self.config.deepseek_final_reward_weight
                    )

                    rewards.append(combined_reward)
                else:
                    rewards.append(0.0)

            except Exception as e:
                logger.error(f"Error calculating reward for sample {i}: {e}")
                rewards.append(0.0)

        # è®°å½•å¥–åŠ±ç»Ÿè®¡
        if rewards:
            avg_reward = sum(rewards) / len(rewards)
            logger.debug(f"Average reward for batch: {avg_reward:.4f}")

        return rewards

    def _parse_response_components(self, response: str) -> tuple:
        """è§£æå“åº”ç»„ä»¶"""
        # ä»å“åº”ä¸­æå–schema, knowledgeç­‰
        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„æ•°æ®æ ¼å¼è¿›è¡Œè§£æ
        schema = ""
        knowledge = ""
        examples = ""

        try:
            # ç®€å•çš„è§£æé€»è¾‘ï¼Œéœ€è¦æ ¹æ®å®é™…æ•°æ®æ ¼å¼è°ƒæ•´
            lines = response.split('\n')
            current_section = None
            section_content = []

            for line in lines:
                if line.startswith('--- 2.schema kg'):
                    current_section = 'schema'
                elif line.startswith('--- 3.knowledge graph'):
                    current_section = 'knowledge'
                elif line.startswith('--- 6.few shot'):
                    current_section = 'examples'
                elif line.startswith('---'):
                    # ç»“æŸå½“å‰section
                    if current_section == 'schema':
                        schema = '\n'.join(section_content)
                    elif current_section == 'knowledge':
                        knowledge = '\n'.join(section_content)
                    elif current_section == 'examples':
                        examples = '\n'.join(section_content)
                    current_section = None
                    section_content = []
                elif current_section:
                    section_content.append(line)

        except Exception as e:
            logger.warning(f"Error parsing response components: {e}")

        return schema, knowledge, examples

    def _parse_query_components(self, query: str) -> tuple:
        """ä»queryä¸­æå–schema, knowledge, examplesç»„ä»¶"""
        schema = ""
        knowledge = ""
        examples = ""

        try:
            lines = query.split('\n')
            current_section = None
            section_content = []

            for line in lines:
                # å…ˆæ£€æŸ¥æ–°çš„sectionæ ‡è®°ï¼Œå¦‚æœæ˜¯æ–°sectionï¼Œå…ˆä¿å­˜å½“å‰section
                if '--- 2.' in line and 'schema' in line.lower():
                    # ä¿å­˜å‰ä¸€ä¸ªsectionï¼ˆå¦‚æœæœ‰ï¼‰
                    if current_section == 'schema':
                        schema = '\n'.join(section_content)
                    elif current_section == 'knowledge':
                        knowledge = '\n'.join(section_content)
                    elif current_section == 'examples':
                        examples = '\n'.join(section_content)

                    current_section = 'schema'
                    section_content = []
                elif '--- 3.' in line and 'knowledge' in line.lower():
                    # ä¿å­˜å‰ä¸€ä¸ªsection
                    if current_section == 'schema':
                        schema = '\n'.join(section_content)
                    elif current_section == 'knowledge':
                        knowledge = '\n'.join(section_content)
                    elif current_section == 'examples':
                        examples = '\n'.join(section_content)

                    current_section = 'knowledge'
                    section_content = []
                elif '--- 6.' in line and 'few' in line.lower():
                    # ä¿å­˜å‰ä¸€ä¸ªsection
                    if current_section == 'schema':
                        schema = '\n'.join(section_content)
                    elif current_section == 'knowledge':
                        knowledge = '\n'.join(section_content)
                    elif current_section == 'examples':
                        examples = '\n'.join(section_content)

                    current_section = 'examples'
                    section_content = []
                elif line.startswith('---'):
                    # å…¶ä»–sectionæ ‡è®°ï¼Œä¿å­˜å½“å‰section
                    if current_section == 'schema':
                        schema = '\n'.join(section_content)
                    elif current_section == 'knowledge':
                        knowledge = '\n'.join(section_content)
                    elif current_section == 'examples':
                        examples = '\n'.join(section_content)
                    current_section = None
                    section_content = []
                elif current_section:
                    section_content.append(line)

            # å¤„ç†æœ€åä¸€ä¸ªsection
            if current_section == 'schema':
                schema = '\n'.join(section_content)
            elif current_section == 'knowledge':
                knowledge = '\n'.join(section_content)
            elif current_section == 'examples':
                examples = '\n'.join(section_content)

        except Exception as e:
            logger.warning(f"Error parsing query components: {e}")

        return schema, knowledge, examples

    def _extract_question_from_query(self, query: str) -> str:
        """ä»queryä¸­æå–å®é™…çš„é—®é¢˜æ–‡æœ¬"""
        try:
            import re

            # æ–¹æ³•1: æŸ¥æ‰¾"é—®é¢˜ï¼š"å’Œ"ï¼Œæå–ä¸­é—´çš„å†…å®¹
            pattern = r'é—®é¢˜ï¼š(.+?)ï¼Œå†™å‡ºå¯¹åº”çš„SQLè¯­å¥'
            match = re.search(pattern, query, re.DOTALL)

            if match:
                question = match.group(1).strip()
                logger.debug(f"Extracted question using pattern: {question[:100]}...")
                return question

            # æ–¹æ³•2: æŸ¥æ‰¾"é—®é¢˜ï¼š"åˆ°"ç­”æ¡ˆï¼š"ä¹‹é—´çš„å†…å®¹
            pattern2 = r'é—®é¢˜ï¼š(.*?)ç­”æ¡ˆï¼š'
            match2 = re.search(pattern2, query, re.DOTALL)
            if match2:
                question = match2.group(1).strip()
                logger.debug(f"Extracted question using pattern2: {question[:100]}...")
                return question

            # æ–¹æ³•3: ä»"é—®é¢˜ï¼š"ä¹‹åï¼Œåˆ°ä¸‹ä¸€ä¸ªç©ºè¡Œæˆ–é€—å·ä¹‹å‰
            if 'é—®é¢˜ï¼š' in query:
                start = query.find('é—®é¢˜ï¼š') + 4
                remaining = query[start:]

                # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªé€—å·ï¼Œæˆ–è€…åœæ­¢åœ¨åˆç†é•¿åº¦
                first_comma = remaining.find('ï¼Œ')
                if first_comma > 0 and first_comma < 500:
                    question = remaining[:first_comma].strip()
                    logger.debug(f"Extracted question using comma: {question[:100]}...")
                    return question

                # å¦‚æœæ²¡æœ‰é€—å·ï¼Œå–å‰200å­—ç¬¦
                if len(remaining) > 0:
                    question = remaining[:200].strip()
                    # ç¡®ä¿ä¸æˆªæ–­åˆ°SQLå…³é”®å­—
                    question = question.split('ï¼Œ')[0].strip()
                    logger.debug(f"Extracted question using fixed length: {question[:100]}...")
                    return question

            # å¦‚æœä»¥ä¸Šæ–¹æ³•éƒ½å¤±è´¥ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²è€Œä¸æ˜¯æ•´ä¸ªquery
            logger.warning(f"Failed to extract question from query, returning empty string")
            return ""

        except Exception as e:
            logger.warning(f"Error extracting question: {e}")
            return ""

    def _parse_training_prompt(self, prompt: str) -> tuple:
        """è§£æè®­ç»ƒæç¤º"""
        try:
            # è¿™é‡Œæ ¹æ®å®é™…æ„å»ºçš„æç¤ºæ ¼å¼è¿›è¡Œè§£æ
            parts = prompt.split('\n\n')
            query = ""
            schema = ""
            knowledge = ""

            for part in parts:
                if part.startswith('é—®é¢˜ï¼š'):
                    query = part.replace('é—®é¢˜ï¼š', '').strip()
                elif part.startswith('Schemaï¼š'):
                    schema = part.replace('Schemaï¼š', '').strip()
                elif part.startswith('ä¸šåŠ¡çŸ¥è¯†ï¼š'):
                    knowledge = part.replace('ä¸šåŠ¡çŸ¥è¯†ï¼š', '').strip()

            return query, schema, knowledge, ""
        except Exception as e:
            logger.error(f"Error parsing training prompt: {e}")
            return "", "", "", ""

    def _build_training_prompt(self, query: str, schema: str, knowledge: str, examples: str) -> str:
        """æ„å»ºè®­ç»ƒæç¤º"""
        prompt_parts = [
            f"é—®é¢˜ï¼š{query}",
            f"Schemaï¼š{schema}",
            f"ä¸šåŠ¡çŸ¥è¯†ï¼š{knowledge}"
        ]
        if examples:
            prompt_parts.append(f"ç¤ºä¾‹ï¼š{examples}")
        return '\n\n'.join(prompt_parts)

    def _extract_sql_from_response(self, response: str) -> str:
        """ä»å“åº”ä¸­æå–SQL"""
        import re
        sql_match = re.search(r'<sql>(.*?)</sql>', response, re.DOTALL | re.IGNORECASE)
        if sql_match:
            return sql_match.group(1).strip()
        return ""

    def _extract_thinking_from_response(self, response: str) -> str:
        """ä»å“åº”ä¸­æå–æ€è€ƒè¿‡ç¨‹"""
        import re
        thinking_match = re.search(r'<thinking>(.*?)</thinking>', response, re.DOTALL | re.IGNORECASE)
        if thinking_match:
            return thinking_match.group(1).strip()
        return ""

    def _extract_self_eval_from_response(self, response: str) -> str:
        """ä»å“åº”ä¸­æå–è‡ªè¯„ä¼°"""
        import re
        eval_match = re.search(r'<self_eval>(.*?)</self_eval>', response, re.DOTALL | re.IGNORECASE)
        if eval_match:
            return eval_match.group(1).strip()
        return ""


def _process_single_sample(params: Dict[str, Any]) -> Dict[str, Any]:
    """
    å¤„ç†å•ä¸ªæ ·æœ¬çš„å‡½æ•°ï¼ˆç”¨äºå¹¶è¡Œå¤„ç†ï¼‰

    Args:
        params: åŒ…å«å‚æ•°çš„å­—å…¸

    Returns:
        å¤„ç†ç»“æœå­—å…¸
    """
    try:
        import sys
        from deepseek_sql.main import DeepSeekNL2SQL

        idx = params['idx']
        query = params['query']
        schema = params['schema']
        knowledge = params['knowledge']
        examples = params['examples']
        reference_type = params['reference_type']
        reference_sql = params['reference_sql']
        model_name = params['model_name']
        pool_dir = params['pool_dir']
        vlm_model_path = params.get('vlm_model_path', None)

        # åˆå§‹åŒ–DeepSeekç³»ç»Ÿï¼ˆæ¯ä¸ªè¿›ç¨‹ç‹¬ç«‹ï¼Œæ”¯æŒVLMï¼‰
        deepseek_system = DeepSeekNL2SQL(
            model_name=model_name,
            pool_dir=pool_dir,
            vlm_model_path=vlm_model_path
        )

        # å¤„ç†æŸ¥è¯¢
        deepseek_result = deepseek_system.process_query(
            query=query,
            schema=schema,
            knowledge=knowledge,
            examples=examples,
            problem_idx=f"train_{idx}"
        )

        if deepseek_result.get('success', False):
            # æ„å»ºè®­ç»ƒæ ·æœ¬
            prompt_parts = [
                f"é—®é¢˜ï¼š{query}",
                f"Schemaï¼š{schema}",
                f"ä¸šåŠ¡çŸ¥è¯†ï¼š{knowledge}"
            ]
            if examples:
                prompt_parts.append(f"ç¤ºä¾‹ï¼š{examples}")

            training_sample = {
                'prompt': '\n\n'.join(prompt_parts),
                'reference': reference_sql or deepseek_result.get('best_sql', ''),
                'reference_type': reference_type,
                'process_reward_data': deepseek_result.get('process_reward', {}),
                'deepseek_result': deepseek_result
            }

            return {
                'success': True,
                'data': training_sample,
                'idx': idx
            }
        else:
            return {'success': False, 'idx': idx}

    except Exception as e:
        import logging
        logging.getLogger(__name__).debug(f"Process sample {params.get('idx', 'unknown')} failed: {e}")
        return {'success': False, 'idx': params.get('idx', 'unknown'), 'error': str(e)}


def load_config(config_file: str) -> DeepSeekTrainingConfig:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open(config_file, 'r', encoding='utf-8') as f:
        config_dict = yaml.safe_load(f)

    # Flatten nested dict if necessary
    if 'training' in config_dict:
        config_dict.update(config_dict['training'])
        del config_dict['training']

    return DeepSeekTrainingConfig(**config_dict)


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="DeepSeek GRPO Training")
    parser.add_argument("--config", type=str, default="config_deepseek.yaml", help="Config file path")
    parser.add_argument("--resume", type=str, default=None, help="Resume from checkpoint")
    # Add GPU configuration arguments
    parser.add_argument("--cuda_visible_devices", type=str, default=None, help="CUDA visible devices (e.g., 0,1,2,3)")
    parser.add_argument("--gpus_per_node", type=int, default=None, help="Number of GPUs per node")
    parser.add_argument("--tensor_model_parallel_size", type=int, default=None, help="Tensor model parallel size")

    args = parser.parse_args()

    # Set GPU-related environment variables
    if args.cuda_visible_devices:
        os.environ["CUDA_VISIBLE_DEVICES"] = args.cuda_visible_devices
        print(f"ğŸ”§ Setting CUDA_VISIBLE_DEVICES={args.cuda_visible_devices}")

    if args.gpus_per_node:
        os.environ["N_GPUS_PER_NODE"] = str(args.gpus_per_node)
        print(f"ğŸ”§ Setting N_GPUS_PER_NODE={args.gpus_per_node}")

    if args.tensor_model_parallel_size:
        os.environ["TENSOR_MODEL_PARALLEL_SIZE"] = str(args.tensor_model_parallel_size)
        print(f"ğŸ”§ Setting TENSOR_MODEL_PARALLEL_SIZE={args.tensor_model_parallel_size}")

    # åŠ è½½é…ç½®
    config = load_config(args.config)

    # å¦‚æœæŒ‡å®šäº†æ¢å¤ç‚¹ï¼Œæ›´æ–°é…ç½®
    if args.resume:
        config.resume_from_checkpoint = args.resume

    # åˆ›å»ºå¹¶è¿è¡Œè®­ç»ƒå™¨
    trainer = DeepSeekGRPOTrainer(config)
    trainer.train()


if __name__ == "__main__":
    main()