"""
éªŒè¯å…«ç§ä»»åŠ¡ç±»å‹æ”¯æŒçš„æ­£ç¡®æ€§
æ£€æŸ¥æ‰€æœ‰ç›¸å…³ä»£ç æ–‡ä»¶æ˜¯å¦æ­£ç¡®æ”¯æŒå…«ç§æ ‡å‡†ä»»åŠ¡ç±»å‹
"""

import json
import logging
from pathlib import Path
from typing import Dict, List, Set

from data.data_loader import NL2SQLDataLoader
from classifiers.complexity_classifier import TaskTypeClassifier
from reward.reward_model import ProcessRewardModel

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å…«ç§æ ‡å‡†ä»»åŠ¡ç±»å‹
EXPECTED_TASK_TYPES = {
    "SQL",  # ç®€å•æ€è€ƒç›´æ¥è¾“å‡ºSQL
    "å¤šæ­¥æ¨ç†",  # å¤šæ­¥éª¤æ€è€ƒï¼Œè¾“å‡ºå¯èƒ½å¸¦æœ‰CTEç­‰çš„å¤æ‚SQL
    "åæ€",  # å°†è¾“å…¥çš„é”™è¯¯SQLæ›´æ­£
    "æ­§ä¹‰æ¾„æ¸…",  # ç”¨æˆ·é—®é¢˜åŒ…å«æ­§ä¹‰ç‚¹ï¼Œè§¦å‘æ¨¡å‹æ€è€ƒ
    "ç»´åº¦æ‹’è¯†",  # ç”¨æˆ·é—®é¢˜åŒ…å«æŸ¥è¯¢ä¸æ”¯æŒçš„ç»´åº¦æ—¶æ¨¡å‹æ‹’ç»å›ç­”
    "ç»´åº¦é€€åŒ–",  # ç»´è¡¨é€€åŒ–åˆ°äº‹å®è¡¨æ—¶ä»æ”¯æŒæŸ¥è¯¢
    "æŒ‡æ ‡æ‹’è¯†",  # ç”¨æˆ·é—®é¢˜åŒ…å«æŸ¥è¯¢ä¸æ”¯æŒçš„æŒ‡æ ‡æ—¶æ¨¡å‹æ‹’ç»å›ç­”
    "è¿½é—®"  # ç”¨æˆ·é—®é¢˜ä¸æ»¡è¶³æŸ¥è¯¢çš„å¿…å¤‡è¦æ±‚
}


class TaskTypeValidator:
    """ä»»åŠ¡ç±»å‹éªŒè¯å™¨"""

    def __init__(self, data_files: List[str]):
        """
        åˆå§‹åŒ–éªŒè¯å™¨

        Args:
            data_files: å¾…éªŒè¯çš„æ•°æ®æ–‡ä»¶åˆ—è¡¨
        """
        self.data_files = data_files
        self.loader = NL2SQLDataLoader()
        self.classifier = TaskTypeClassifier()
        self.reward_model = ProcessRewardModel()
        self.validation_results = {}

    def validate_all(self) -> Dict:
        """
        æ‰§è¡Œæ‰€æœ‰éªŒè¯æµ‹è¯•

        Returns:
            éªŒè¯ç»“æœå­—å…¸
        """
        logger.info("="*60)
        logger.info("å¼€å§‹éªŒè¯å…«ç§ä»»åŠ¡ç±»å‹æ”¯æŒ")
        logger.info("="*60)

        # 1. éªŒè¯æ•°æ®æ–‡ä»¶ä¸­çš„ä»»åŠ¡ç±»å‹
        self._validate_data_file_task_types()

        # 2. éªŒè¯åˆ†ç±»å™¨å¯¹å…«ç§ç±»å‹çš„æ”¯æŒ
        self._validate_classifier_support()

        # 3. éªŒè¯å¥–åŠ±æ¨¡å‹å¯¹å…«ç§ç±»å‹çš„æ”¯æŒ
        self._validate_reward_model_support()

        # 4. éªŒè¯æ•°æ®åŠ è½½å™¨çš„ç±»å‹å¤„ç†
        self._validate_data_loader_support()

        # 5. ç”ŸæˆéªŒè¯æŠ¥å‘Š
        self._generate_validation_report()

        return self.validation_results

    def _validate_data_file_task_types(self):
        """éªŒè¯æ•°æ®æ–‡ä»¶ä¸­çš„ä»»åŠ¡ç±»å‹"""
        logger.info("\n1. éªŒè¯æ•°æ®æ–‡ä»¶ä¸­çš„ä»»åŠ¡ç±»å‹åˆ†å¸ƒ")
        logger.info("-"*50)

        task_type_counts = {}
        all_found_types = set()

        for data_file in self.data_files:
            logger.info(f"\næ£€æŸ¥æ–‡ä»¶: {data_file}")
            examples = self.loader.load(data_file, use_cache=False)

            for example in examples:
                task_type = example.task_type
                task_type_counts[task_type] = task_type_counts.get(task_type, 0) + 1
                all_found_types.add(task_type)

        # æ£€æŸ¥æ˜¯å¦æœ‰æœªé¢„æœŸçš„ä»»åŠ¡ç±»å‹
        unexpected_types = all_found_types - EXPECTED_TASK_TYPES
        missing_types = EXPECTED_TASK_TYPES - all_found_types

        self.validation_results['data_file_validation'] = {
            'task_type_counts': task_type_counts,
            'found_types': list(all_found_types),
            'unexpected_types': list(unexpected_types),
            'missing_types': list(missing_types),
            'is_valid': len(unexpected_types) == 0
        }

        logger.info(f"å‘ç°çš„ä»»åŠ¡ç±»å‹: {sorted(all_found_types)}")
        logger.info(f"ä»»åŠ¡ç±»å‹åˆ†å¸ƒ: {task_type_counts}")

        if unexpected_types:
            logger.warning(f"å‘ç°æœªé¢„æœŸçš„ä»»åŠ¡ç±»å‹: {sorted(unexpected_types)}")

        if missing_types:
            logger.warning(f"ç¼ºå¤±çš„ä»»åŠ¡ç±»å‹: {sorted(missing_types)}")

    def _validate_classifier_support(self):
        """éªŒè¯åˆ†ç±»å™¨å¯¹å…«ç§ç±»å‹çš„æ”¯æŒ"""
        logger.info("\n2. éªŒè¯åˆ†ç±»å™¨å¯¹å…«ç§ç±»å‹çš„æ”¯æŒ")
        logger.info("-"*50)

        classifier_issues = []

        # æ£€æŸ¥åˆ†ç±»å™¨æ”¯æŒçš„ç±»å‹
        for task_type in EXPECTED_TASK_TYPES:
            # åˆ›å»ºæµ‹è¯•æ ·æœ¬
            test_sql = "SELECT 1" if task_type in ["SQL", "å¤šæ­¥æ¨ç†", "åæ€", "ç»´åº¦é€€åŒ–"] else ""
            test_query = f"æµ‹è¯•{task_type}ç±»é—®é¢˜"

            try:
                result = self.classifier.classify(test_sql, test_query, task_type)

                if result.task_type != task_type:
                    classifier_issues.append(f"{task_type}: é¢„æœŸç±»å‹ä¸åŒ¹é… (é¢„æœŸ: {task_type}, å®é™…: {result.task_type})")

                logger.info(f"âœ“ {task_type}: åˆ†ç±»æˆåŠŸï¼Œä»»åŠ¡ç±»å‹={result.task_type}")
            except Exception as e:
                classifier_issues.append(f"{task_type}: åˆ†ç±»å¤±è´¥ - {str(e)}")
                logger.error(f"âœ— {task_type}: åˆ†ç±»å¤±è´¥ - {str(e)}")

        self.validation_results['classifier_validation'] = {
            'issues': classifier_issues,
            'is_valid': len(classifier_issues) == 0
        }

        if classifier_issues:
            logger.error(f"\nåˆ†ç±»å™¨é—®é¢˜ ({len(classifier_issues)}ä¸ª):")
            for issue in classifier_issues:
                logger.error(f"  - {issue}")
        else:
            logger.info("\nâœ“ æ‰€æœ‰ä»»åŠ¡ç±»å‹åˆ†ç±»é€šè¿‡")

    def _validate_reward_model_support(self):
        """éªŒè¯å¥–åŠ±æ¨¡å‹å¯¹å…«ç§ç±»å‹çš„æ”¯æŒ"""
        logger.info("\n3. éªŒè¯å¥–åŠ±æ¨¡å‹å¯¹å…«ç§ç±»å‹çš„æ”¯æŒ")
        logger.info("-"*50)

        reward_issues = []

        # æ£€æŸ¥å¥–åŠ±æ¨¡å‹æ”¯æŒçš„ç±»å‹
        for task_type in EXPECTED_TASK_TYPES:
            test_sql = "SELECT 1" if task_type in ["SQL", "å¤šæ­¥æ¨ç†", "åæ€", "ç»´åº¦é€€åŒ–"] else ""
            test_thinking = f"è¿™æ˜¯{task_type}ç±»ä»»åŠ¡çš„æ¨ç†è¿‡ç¨‹"
            test_query = f"æµ‹è¯•{task_type}ç±»é—®é¢˜"

            try:
                reward_dict = self.reward_model.compute_reward(
                    generated_sql=test_sql,
                    predicted_type=task_type,
                    thinking=test_thinking,
                    reference_type=task_type,
                    reference_sql=test_sql,
                    query=test_query
                )

                # æ£€æŸ¥å¥–åŠ±å€¼èŒƒå›´
                total_reward = reward_dict['total_reward']
                if not (0 <= total_reward <= 1):
                    reward_issues.append(f"{task_type}: å¥–åŠ±å€¼è¶…å‡ºèŒƒå›´ [0,1] - {total_reward}")

                # æ£€æŸ¥å¯è®­ç»ƒæ€§æ ‡è®°
                is_trainable = reward_dict['is_trainable']
                expected_trainable = task_type in ProcessRewardModel.TRAINABLE_TASK_TYPES
                if is_trainable != expected_trainable:
                    reward_issues.append(f"{task_type}: å¯è®­ç»ƒæ€§æ ‡è®°é”™è¯¯ (é¢„æœŸ: {expected_trainable}, å®é™…: {is_trainable})")

                logger.info(f"âœ“ {task_type}: å¥–åŠ±è®¡ç®—æˆåŠŸï¼Œæ€»å¥–åŠ±={total_reward:.4f}ï¼Œå¯è®­ç»ƒ={is_trainable}")
            except Exception as e:
                reward_issues.append(f"{task_type}: å¥–åŠ±è®¡ç®—å¤±è´¥ - {str(e)}")
                logger.error(f"âœ— {task_type}: å¥–åŠ±è®¡ç®—å¤±è´¥ - {str(e)}")

        self.validation_results['reward_model_validation'] = {
            'issues': reward_issues,
            'is_valid': len(reward_issues) == 0
        }

        if reward_issues:
            logger.error(f"\nå¥–åŠ±æ¨¡å‹é—®é¢˜ ({len(reward_issues)}ä¸ª):")
            for issue in reward_issues:
                logger.error(f"  - {issue}")
        else:
            logger.info("\nâœ“ æ‰€æœ‰ä»»åŠ¡ç±»å‹å¥–åŠ±è®¡ç®—é€šè¿‡")

    def _validate_data_loader_support(self):
        """éªŒè¯æ•°æ®åŠ è½½å™¨çš„ç±»å‹å¤„ç†"""
        logger.info("\n4. éªŒè¯æ•°æ®åŠ è½½å™¨çš„ç±»å‹å¤„ç†")
        logger.info("-"*50)

        loader_issues = []
        trainable_examples = 0
        non_trainable_examples = 0

        for data_file in self.data_files:
            examples = self.loader.load(data_file, use_cache=False)

            for example in examples:
                task_type = example.task_type

                # æ£€æŸ¥å¤æ‚åº¦ç±»å‹å…¼å®¹æ€§
                complexity_type = example.complexity_type

                # å¯¹äºå¯è®­ç»ƒç±»å‹ï¼Œå¤æ‚åº¦ç±»å‹åº”è¯¥æ˜¯sqlæˆ–å¤šæ­¥æ¨ç†
                if example.is_trainable:
                    if task_type == "å¤šæ­¥æ¨ç†":
                        expected_complexity = "å¤šæ­¥æ¨ç†"
                    else:
                        expected_complexity = "sql"

                    if complexity_type != expected_complexity:
                        loader_issues.append(f"{task_type}: å¤æ‚åº¦ç±»å‹ä¸åŒ¹é… (é¢„æœŸ: {expected_complexity}, å®é™…: {complexity_type})")

                # æ£€æŸ¥å¯è®­ç»ƒæ€§
                if example.is_trainable:
                    trainable_examples += 1
                    if task_type in ProcessRewardModel.NON_TRAINABLE_TASK_TYPES:
                        loader_issues.append(f"{task_type}: åº”è¯¥æ˜¯ä¸å¯è®­ç»ƒçš„ä½†è¢«æ ‡è®°ä¸ºå¯è®­ç»ƒ")
                else:
                    non_trainable_examples += 1
                    if task_type in ProcessRewardModel.TRAINABLE_TASK_TYPES:
                        logger.warning(f"{task_type}: åº”è¯¥æ˜¯å¯è®­ç»ƒçš„ä½†è¢«æ ‡è®°ä¸ºä¸å¯è®­ç»ƒ")

        self.validation_results['data_loader_validation'] = {
            'issues': loader_issues[:10],  # åªæ˜¾ç¤ºå‰10ä¸ªé”™è¯¯ï¼Œé¿å…è¾“å‡ºè¿‡é•¿
            'total_issues': len(loader_issues),
            'trainable_examples': trainable_examples,
            'non_trainable_examples': non_trainable_examples,
            'is_valid': len(loader_issues) == 0
        }

        logger.info(f"å¯è®­ç»ƒæ ·æœ¬: {trainable_examples}")
        logger.info(f"éè®­ç»ƒæ ·æœ¬: {non_trainable_examples}")

        if loader_issues:
            logger.error(f"\næ•°æ®åŠ è½½å™¨é—®é¢˜ ({len(loader_issues)}ä¸ª):")
            for issue in loader_issues:
                logger.error(f"  - {issue}")
        else:
            logger.info("\nâœ“ æ•°æ®åŠ è½½å™¨ç±»å‹å¤„ç†é€šè¿‡")

    def _generate_validation_report(self):
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        logger.info("\n5. ç”ŸæˆéªŒè¯æŠ¥å‘Š")
        logger.info("="*50)

        # æ±‡æ€»éªŒè¯ç»“æœ
        all_validations = [
            self.validation_results['data_file_validation']['is_valid'],
            self.validation_results['classifier_validation']['is_valid'],
            self.validation_results['reward_model_validation']['is_valid'],
            self.validation_results['data_loader_validation']['is_valid']
        ]

        overall_valid = all(all_validations)

        self.validation_results['overall_valid'] = overall_valid
        self.validation_results['summary'] = {
            'data_files_checked': len(self.data_files),
            'expected_task_types': len(EXPECTED_TASK_TYPES),
            'validations_passed': sum(all_validations),
            'validations_total': len(all_validations)
        }

        # ä¿å­˜æŠ¥å‘Š
        report_file = "./outputs/validation_report.json"
        Path(report_file).parent.mkdir(parents=True, exist_ok=True)

        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(self.validation_results, f, ensure_ascii=False, indent=2)

        logger.info(f"\néªŒè¯æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}\n")

        # æ‰“å°æ±‡æ€»
        logger.info("éªŒè¯æ±‡æ€»:")
        logger.info(f"- æ•°æ®æ–‡ä»¶éªŒè¯: {'âœ“ é€šè¿‡' if all_validations[0] else 'âœ— å¤±è´¥'}")
        logger.info(f"- åˆ†ç±»å™¨éªŒè¯: {'âœ“ é€šè¿‡' if all_validations[1] else 'âœ— å¤±è´¥'}")
        logger.info(f"- å¥–åŠ±æ¨¡å‹éªŒè¯: {'âœ“ é€šè¿‡' if all_validations[2] else 'âœ— å¤±è´¥'}")
        logger.info(f"- æ•°æ®åŠ è½½å™¨éªŒè¯: {'âœ“ é€šè¿‡' if all_validations[3] else 'âœ— å¤±è´¥'}")

        if overall_valid:
            logger.info("\nğŸ‰ æ‰€æœ‰éªŒè¯é€šè¿‡ï¼å…«ç§ä»»åŠ¡ç±»å‹æ”¯æŒæ­£å¸¸ã€‚")
        else:
            logger.error("\nâŒ éªŒè¯å¤±è´¥ï¼è¯·æ£€æŸ¥ä¸Šè¿°é—®é¢˜å¹¶ä¿®å¤ã€‚")


def main():
    """ä¸»å‡½æ•°"""
    # è¦éªŒè¯çš„æ•°æ®æ–‡ä»¶
    data_files = [
        "./data/nl2_sql_cold_start_sft_all_train_swift_9501_1231.json",
        "./data/nl2_sql_cold_start_sft_all_test_swift_830_1231.json"
    ]

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    existing_files = []
    for file_path in data_files:
        if Path(file_path).exists():
            existing_files.append(file_path)
        else:
            logger.warning(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

    if not existing_files:
        logger.error("æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ•°æ®æ–‡ä»¶ï¼ŒéªŒè¯ç»ˆæ­¢")
        return

    # æ‰§è¡ŒéªŒè¯
    validator = TaskTypeValidator(existing_files)
    results = validator.validate_all()

    # æ ¹æ®éªŒè¯ç»“æœè®¾ç½®é€€å‡ºç 
    exit_code = 0 if results['overall_valid'] else 1
    exit(exit_code)


if __name__ == "__main__":
    main()